import matplotlib.pyplot as plt
import pandas as pd
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from colorama import Fore
from tabulate import tabulate

import FeatureExtractor


def displayTop10Features(df):
    fig, axs = plt.subplots(nrows=2, sharex=True)
    pd.Series.sort_values(df[df.type == 0].sum(axis=0), ascending=False)[1:11].plot.bar(ax=axs[0], title="Benign")
    pd.Series.sort_values(df[df.type == 1].sum(axis=0), ascending=False)[1:11].plot.bar(ax=axs[1], title="Malign",
                                                                                        color="red")
    plt.show()


def runNaiveBayesModel(X_test, X_train, y_test, y_train):
    # Naive Bayes algorithm
    gnb = GaussianNB()
    gnb.fit(X_train, y_train)
    # pred
    pred = gnb.predict(X_test)
    # accuracy
    accuracy = accuracy_score(pred, y_test)
    print("naive_bayes")
    print(accuracy)
    print(classification_report(pred, y_test, labels=None))
    return gnb, pred


def runKNeighborsModel(X_test, X_train, y_test, y_train):
    # kneighbors algorithm
    for i in range(3, 15, 3):
        neigh = KNeighborsClassifier(n_neighbors=i)
        neigh.fit(X_train, y_train)
        pred = neigh.predict(X_test)
        # accuracy
        accuracy = accuracy_score(pred, y_test)
        print("kneighbors {}".format(i))
        print(accuracy)
        print(classification_report(pred, y_test, labels=None))
        print("")


def runDecisionTreeClassifierModel(X_test, X_train, y_test, y_train):
    # Decision Tree Classifier
    clf = tree.DecisionTreeClassifier()
    clf.fit(X_train, y_train)
    # Read the csv test file
    pred = clf.predict(X_test)
    # accuracy
    accuracy = accuracy_score(pred, y_test)
    print(clf)
    print(accuracy)
    print(classification_report(pred, y_test, labels=None))


def randomForestClassifierModel(X_test, X_train, y_test, y_train):
    # Random Forest Classifier
    clf = RandomForestClassifier()
    clf.fit(X_train, y_train)
    # Read the csv test file
    pred = clf.predict(X_test)
    # accuracy
    accuracy = accuracy_score(pred, y_test)
    print("\n\n\n")
    print(clf)
    print(accuracy)
    print(classification_report(pred, y_test, labels=None))
    return clf, pred


def runMultipleModels(X_test, X_train, y_test, y_train):
    models = [RandomForestClassifier, DecisionTreeClassifier, KNeighborsClassifier, AdaBoostClassifier, SGDClassifier,
              ExtraTreesClassifier, GaussianNB]
    accuracy_test = []
    model = []
    for m in models:
        model_name = type(m()).__name__
        print('######-Model =>\033[07m {} \033[0m'.format(type(m()).__name__))
        model_ = m()
        model_.fit(X_train, y_train)
        pred = model_.predict(X_test)
        acc = accuracy_score(pred, y_test)
        accuracy_test.append(acc)
        model.append(model_name)
        print('Test Accuracy :\033[32m \033[01m {:.5f}% \033[30m \033[0m'.format(acc * 100))
        print('\033[01m              Classification_report \033[0m')
        print(classification_report(y_test, pred))
        print('\033[31m###################- End -###################\033[0m')
        print("\n\n\n")

    model = pd.Series(model, name='Model').astype(str)
    accuracy = pd.Series(accuracy_test, name='Accuracy')
    output = pd.concat([model, accuracy], axis=1)
    print(output)


def evaluateForTestData(model, X_test, y_test, pred):
    j = 0
    print(f"Test Sample Size : {len(X_test)}")
    print('\033[07m {} \033[0m'.format("Model=>Random Forest Classifier"))
    list = []
    for i in X_test.index:
        each = []
        actualPred = "malicious" if pred[j] == 1 else "benign"
        expectedPred = "malicious" if y_test[j] == 1 else "benign"
        color = Fore.GREEN if actualPred == expectedPred else Fore.RED
        # print(color + f"App Name: {i} Expected : {expectedPred} Actual: {actualPred}")
        each.append(color + f"{i}")
        each.append(color + f"{expectedPred}")
        each.append(color + f"{actualPred}")
        list.append(each)
        j = j + 1

    print(tabulate(list, headers=['AppName', 'Expected', 'Actual']))


def Main():
    ExtractorAIO.Extractor(CSV_FILE_NAME, USES_PERMISSION, USES_FEATURE, USES_INTENT_ACTIONS)

    df = pd.read_csv("./" + CSV_FILE_NAME, sep=",")
    print(f"shape of the data Set: {df.shape}")
    df = df.set_index("name")
    print(f"shape of the data Set after indexing : {df.shape}")
    # displayTop10Features(df)

    X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, 0:-1], df['type'], test_size=0.2, random_state=42)
    runMultipleModels(X_test, X_train, y_test, y_train)

    ##runNaiveBayesModel(X_test, X_train, y_test, y_train)

    # runKNeighborsModel(X_test, X_train, y_test, y_train)

    # runDecisionTreeClassifierModel(X_test, X_train, y_test, y_train)

    model, pred = randomForestClassifierModel(X_test, X_train, y_test, y_train)
    evaluateForTestData(model, X_test, y_test, pred)


CSV_FILE_NAME = "data.csv"
USES_PERMISSION = True
USES_FEATURE = True
USES_INTENT_ACTIONS = True

if __name__ == '__main__':
    Main()
